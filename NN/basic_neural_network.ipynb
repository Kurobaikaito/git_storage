{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dcf78c-e572-4717-92ae-5f39187dd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import matplotlib as plt\n",
    "\n",
    "from nndl.op import Op\n",
    "\n",
    "# 实现线性层算子\n",
    "class Linear(Op):\n",
    "    ##构造函数\n",
    "    def __init__(self, input_size, output_size, name, weight_init=paddle.standard_normal, bias_init=paddle.zeros):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - input_size：输入数据维度\n",
    "            - output_size：输出数据维度\n",
    "            - name：算子名称\n",
    "            - weight_init：权重初始化方式，默认使用'paddle.standard_normal'进行标准正态分布初始化\n",
    "            - bias_init：偏置初始化方式，默认使用全0初始化\n",
    "        \"\"\"\n",
    "        \n",
    "        self.params = {}\n",
    "        # 初始化权重\n",
    "        self.params['W'] = weight_init(shape=[input_size,output_size])\n",
    "        # 初始化偏置\n",
    "        self.params['b'] = bias_init(shape=[1,output_size])\n",
    "        self.inputs = None\n",
    "\n",
    "        self.name = name\n",
    "        self.grads = {}\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - inputs：shape=[N,input_size], N是样本数量\n",
    "        输出：\n",
    "            - outputs：预测值，shape=[N,output_size]\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "\n",
    "        outputs = paddle.matmul(self.inputs, self.params['W']) + self.params['b']\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, grads):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - grads：损失函数对当前层输出的导数\n",
    "        输出：\n",
    "            - 损失函数对当前层输入的导数\n",
    "        \"\"\"\n",
    "        self.grads['W'] = paddle.matmul(self.inputs.T, grads)\n",
    "        self.grads['b'] = paddle.sum(grads, axis=0)\n",
    "\n",
    "        # 线性层输入的梯度\n",
    "        return paddle.matmul(grads, self.params['W'].T)\n",
    "\n",
    "class Logistic(Op):\n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.params = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - inputs: shape=[N,D]\n",
    "        输出：\n",
    "            - outputs：shape=[N,D]\n",
    "        \"\"\"\n",
    "        outputs = 1.0 / (1.0 + paddle.exp(-inputs))\n",
    "        self.outputs = outputs\n",
    "        return outputs\n",
    "\n",
    "    def backward(self, grads):\n",
    "        # 计算Logistic激活函数对输入的导数\n",
    "        outputs_grad_inputs = paddle.multiply(self.outputs, (1.0 - self.outputs))\n",
    "        return paddle.multiply(grads,outputs_grad_inputs)\n",
    "\n",
    "class Model_MLP_L2(Op):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - input_size：输入维度\n",
    "            - hidden_size：隐藏层神经元数量\n",
    "            - output_size：输出维度\n",
    "        \"\"\"\n",
    "        self.fc1 = Linear(input_size, hidden_size, name=\"fc1\")\n",
    "        self.act_fn1 = Logistic()\n",
    "        self.fc2 = Linear(hidden_size, output_size, name=\"fc2\")\n",
    "        self.act_fn2 = Logistic()\n",
    "\n",
    "        self.layers = [self.fc1,self.act_fn1,self.fc2,self.act_fn2]\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - X：shape=[N,input_size], N是样本数量\n",
    "        输出：\n",
    "            - a2：预测值，shape=[N,output_size]\n",
    "        \"\"\"\n",
    "        z1 = self.fc1(X) ##first layer\n",
    "        a1 = self.act_fn1(z1) ##first active function\n",
    "        z2 = self.fc2(a1) ## second layer\n",
    "        a2 = self.act_fn2(z2) ## second active function\n",
    "        return a2 ##output\n",
    "\n",
    "    def backward(self, loss_grad_a2):\n",
    "        loss_grad_z2 = self.act_fn2.backward(loss_grad_a2)\n",
    "        loss_grad_a1 = self.fc2.backward(loss_grad_z2)\n",
    "        loss_grad_z1 = self.act_fn1.backward(loss_grad_a1)\n",
    "        loss_grad_inputs = self.fc1.backward(loss_grad_z1)\n",
    "\n",
    "# 实现交叉熵损失函数\n",
    "class BinaryCrossEntropyLoss(Op):\n",
    "    def __init__(self, model):\n",
    "        self.predicts = None\n",
    "        self.labels = None\n",
    "        self.num = None\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, predicts, labels):\n",
    "        return self.forward(predicts, labels)\n",
    "\n",
    "    def forward(self, predicts, labels):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "            - predicts：预测值，shape=[N, 1]，N为样本数量\n",
    "            - labels：真实标签，shape=[N, 1]\n",
    "        输出：\n",
    "            - 损失值：shape=[1]\n",
    "        \"\"\"\n",
    "        self.predicts = predicts\n",
    "        self.labels = labels\n",
    "        self.num = self.predicts.shape[0]\n",
    "        loss = -1. / self.num * (paddle.matmul(self.labels.t(), paddle.log(self.predicts)) \n",
    "                + paddle.matmul((1-self.labels.t()), paddle.log(1-self.predicts)))\n",
    "\n",
    "        loss = paddle.squeeze(loss, axis=1)\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        # 计算损失函数对模型预测的导数\n",
    "        loss_grad_predicts = -1.0 * (self.labels / self.predicts - \n",
    "                       (1 - self.labels) / (1 - self.predicts)) / self.num\n",
    "        \n",
    "        # 梯度反向传播\n",
    "        self.model.backward(loss_grad_predicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fd8e4-6607-476c-8fa3-3f07807ef74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
